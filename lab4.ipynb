{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4418ab5",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorio #3 – CNN con MNIST (Pasos 2 y 3)\n",
    "**Curso:** Inteligencia Artificial  \n",
    "**Tema:** Convolutional Neural Networks (CNN)  \n",
    "**Dataset:** MNIST (28×28, 10 clases)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf18066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time, itertools\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fb3364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10               #\n",
    "LR = 1e-3\n",
    "DATA_DIR = \"./data\"      \n",
    "VAL_SPLIT = 10_000       \n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80026b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Datos: MNIST con normalización estándar\n",
    "# Promedio y desviación típica de MNIST en escala [0,1]:\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "try:\n",
    "    full_train = datasets.MNIST(root=DATA_DIR, train=True, transform=transform, download=True)\n",
    "    test_ds = datasets.MNIST(root=DATA_DIR, train=False, transform=transform, download=True)\n",
    "except Exception as e:\n",
    "    print(\" No se pudo descargar/cargar MNIST automáticamente.\")\n",
    "    print(\"   Error:\", e)\n",
    "    print(\"   Solución: Descarga manualmente MNIST y coloca los archivos en\", DATA_DIR)\n",
    "    raise\n",
    "\n",
    "# División train/val\n",
    "train_size = len(full_train) - VAL_SPLIT\n",
    "val_size = VAL_SPLIT\n",
    "train_ds, val_ds = random_split(full_train, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a858d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utilidades: conteo de parámetros, accuracy, bucles de train/eval, matriz de confusión\n",
    "\n",
    "def count_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def accuracy_from_logits(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds == y).sum().item()\n",
    "    return correct / y.size(0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_count = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        total_correct += (logits.argmax(1) == y).sum().item()\n",
    "        total_count += y.size(0)\n",
    "    return total_loss / total_count, total_correct / total_count\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, running_correct, running_count = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "        running_correct += (logits.argmax(1) == y).sum().item()\n",
    "        running_count += y.size(0)\n",
    "    return running_loss / running_count, running_correct / running_count\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=EPOCHS):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    best_val = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        print(f\"Epoch {ep:02d}/{epochs} | Train Loss {tr_loss:.4f} Acc {tr_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return history\n",
    "\n",
    "@torch.no_grad()\n",
    "def confusion_matrix(model: nn.Module, loader: DataLoader, num_classes: int = 10, device: torch.device = torch.device(\"cpu\")) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.int64)\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1)\n",
    "        for t, p in zip(y.view(-1), preds.view(-1)):\n",
    "            cm[t.long(), p.long()] += 1\n",
    "    return cm.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6477bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelos \n",
    "class MLPBaseline(nn.Module):\n",
    "    def __init__(self, hidden1: int = 256, hidden2: int = 128, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, hidden1), nn.ReLU(),\n",
    "            nn.Linear(hidden1, hidden2), nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden2, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, c1: int = 16, c2: int = 32, fc_hidden: int = 128, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        # Bloque 1: Conv -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c1, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Bloque 2: Conv -> ReLU -> MaxPool\n",
    "        self.conv2 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Tamaño tras dos poolings (28x28 -> 14x14 -> 7x7)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(c2 * 7 * 7, fc_hidden)\n",
    "        self.fc_out = nn.Linear(fc_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62709741",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 2 — Construcción y experimentos de la CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d572da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimento CNN: {'model': 'cnn', 'c1': 16, 'c2': 32, 'fc_hidden': 128, 'opt': 'adam', 'lr': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eduar\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/10 | Train Loss 0.2593 Acc 0.9245 | Val Loss 0.0926 Acc 0.9740\n",
      "Epoch 02/10 | Train Loss 0.0665 Acc 0.9796 | Val Loss 0.0577 Acc 0.9833\n",
      "Epoch 03/10 | Train Loss 0.0479 Acc 0.9851 | Val Loss 0.0510 Acc 0.9859\n",
      "Epoch 04/10 | Train Loss 0.0343 Acc 0.9895 | Val Loss 0.0518 Acc 0.9845\n",
      "Epoch 05/10 | Train Loss 0.0282 Acc 0.9911 | Val Loss 0.0492 Acc 0.9855\n",
      "Epoch 06/10 | Train Loss 0.0239 Acc 0.9924 | Val Loss 0.0461 Acc 0.9861\n",
      "Epoch 07/10 | Train Loss 0.0165 Acc 0.9950 | Val Loss 0.0401 Acc 0.9882\n",
      "Epoch 08/10 | Train Loss 0.0146 Acc 0.9952 | Val Loss 0.0411 Acc 0.9886\n",
      "Epoch 09/10 | Train Loss 0.0115 Acc 0.9962 | Val Loss 0.0447 Acc 0.9880\n",
      "Epoch 10/10 | Train Loss 0.0108 Acc 0.9964 | Val Loss 0.0438 Acc 0.9890\n",
      "\n",
      "Experimento CNN: {'model': 'cnn', 'c1': 32, 'c2': 64, 'fc_hidden': 256, 'opt': 'sgd', 'lr': 0.01}\n",
      "Epoch 01/10 | Train Loss 0.3268 Acc 0.9038 | Val Loss 0.1122 Acc 0.9638\n",
      "Epoch 02/10 | Train Loss 0.0689 Acc 0.9789 | Val Loss 0.0617 Acc 0.9816\n",
      "Epoch 03/10 | Train Loss 0.0481 Acc 0.9850 | Val Loss 0.0612 Acc 0.9818\n",
      "Epoch 04/10 | Train Loss 0.0385 Acc 0.9879 | Val Loss 0.0463 Acc 0.9867\n",
      "Epoch 05/10 | Train Loss 0.0301 Acc 0.9908 | Val Loss 0.0436 Acc 0.9866\n",
      "Epoch 06/10 | Train Loss 0.0239 Acc 0.9928 | Val Loss 0.0434 Acc 0.9874\n",
      "Epoch 07/10 | Train Loss 0.0197 Acc 0.9936 | Val Loss 0.0391 Acc 0.9887\n",
      "Epoch 08/10 | Train Loss 0.0160 Acc 0.9952 | Val Loss 0.0376 Acc 0.9896\n",
      "Epoch 09/10 | Train Loss 0.0138 Acc 0.9954 | Val Loss 0.0406 Acc 0.9886\n",
      "Epoch 10/10 | Train Loss 0.0111 Acc 0.9965 | Val Loss 0.0387 Acc 0.9896\n",
      "\n",
      "Experimento CNN: {'model': 'cnn', 'c1': 8, 'c2': 16, 'fc_hidden': 64, 'opt': 'adam', 'lr': 0.001}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m model = SimpleCNN(c1=cfg[\u001b[33m\"\u001b[39m\u001b[33mc1\u001b[39m\u001b[33m\"\u001b[39m], c2=cfg[\u001b[33m\"\u001b[39m\u001b[33mc2\u001b[39m\u001b[33m\"\u001b[39m], fc_hidden=cfg[\u001b[33m\"\u001b[39m\u001b[33mfc_hidden\u001b[39m\u001b[33m\"\u001b[39m]).to(device)\n\u001b[32m     24\u001b[39m opt = make_optimizer(cfg[\u001b[33m\"\u001b[39m\u001b[33mopt\u001b[39m\u001b[33m\"\u001b[39m], model.parameters(), lr=cfg[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m hist = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n\u001b[32m     28\u001b[39m test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, device, epochs)\u001b[39m\n\u001b[32m     43\u001b[39m best_state = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     tr_loss, tr_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n\u001b[32m     48\u001b[39m     history[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(tr_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     28\u001b[39m x, y = x.to(device), y.to(device)\n\u001b[32m     29\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m loss = criterion(logits, y)\n\u001b[32m     32\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mSimpleCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     33\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool1(x)\n\u001b[32m     34\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m     37\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.fc1(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\pooling.py:213\u001b[39m, in \u001b[36mMaxPool2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\_jit_internal.py:622\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\functional.py:830\u001b[39m, in \u001b[36m_max_pool2d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    829\u001b[39m     stride = torch.jit.annotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def make_optimizer(name: str, params, lr: float):\n",
    "    name = name.lower()\n",
    "    if name == \"adam\":\n",
    "        return torch.optim.Adam(params, lr=lr)\n",
    "    elif name == \"sgd\":\n",
    "        return torch.optim.SGD(params, lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizador no reconocido: {name}\")\n",
    "\n",
    "# Lista de configuraciones de CNN a probar\n",
    "cnn_experiments = [\n",
    "    {\"model\": \"cnn\", \"c1\": 16, \"c2\": 32, \"fc_hidden\": 128, \"opt\": \"adam\", \"lr\": 1e-3},\n",
    "    {\"model\": \"cnn\", \"c1\": 32, \"c2\": 64, \"fc_hidden\": 256, \"opt\": \"sgd\",  \"lr\": 0.01},\n",
    "    {\"model\": \"cnn\", \"c1\": 8,  \"c2\": 16, \"fc_hidden\": 64,  \"opt\": \"adam\", \"lr\": 1e-3},\n",
    "]\n",
    "\n",
    "results: List[Dict[str, Any]] = []\n",
    "\n",
    "for cfg in cnn_experiments:\n",
    "    print(\"\\nExperimento CNN:\", cfg, )\n",
    "    model = SimpleCNN(c1=cfg[\"c1\"], c2=cfg[\"c2\"], fc_hidden=cfg[\"fc_hidden\"]).to(device)\n",
    "    opt = make_optimizer(cfg[\"opt\"], model.parameters(), lr=cfg[\"lr\"])\n",
    "\n",
    "    hist = train_model(model, train_loader, val_loader, opt, criterion, device, epochs=EPOCHS)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    params = count_params(model)\n",
    "\n",
    "    results.append({\n",
    "        \"name\": f\"CNN(c1={cfg['c1']},c2={cfg['c2']},fc={cfg['fc_hidden']},{cfg['opt']})\",\n",
    "        \"type\": \"CNN\",\n",
    "        \"val_acc\": val_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"params\": params,\n",
    "        \"model_obj\": model,  \n",
    "    })\n",
    "\n",
    "# Mostrar resultados ordenados por val_acc\n",
    "results_sorted = sorted(results, key=lambda d: d[\"val_acc\"], reverse=True)\n",
    "for r in results_sorted:\n",
    "    print(f\"{r['name']}: val_acc={r['val_acc']:.4f}, test_acc={r['test_acc']:.4f}, params={r['params']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce08dc6",
   "metadata": {},
   "source": [
    "\n",
    "### Línea base (laboratorio anterior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes, activation_fn):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if out_dim != layer_sizes[-1]:\n",
    "                layers.append(activation_fn())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "BaselineAnterior = MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41538e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_cfg = {\"hidden1\": 256, \"hidden2\": 128, \"opt\": \"adam\", \"lr\": 1e-3}\n",
    "\n",
    "print(\"\\nEntrenando modelo anterior\")\n",
    "\n",
    "use_user_baseline = False\n",
    "baseline = None\n",
    "\n",
    "try:\n",
    "    BaselineAnterior  \n",
    "    try:\n",
    "        baseline = BaselineAnterior().to(device)\n",
    "        use_user_baseline = True\n",
    "        print(\"Usando BaseLine anterior\")\n",
    "    except TypeError as e:\n",
    "        print(\"La clase BaselineAnterior requiere argumentos:\", e)\n",
    "        print(\" Ajustar la instanciación aquí para pasar los parámetros adecuados.\")\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "if baseline is None:\n",
    "    print(\"Usando fallback MLPBaseline()\")\n",
    "    baseline = MLPBaseline(hidden1=baseline_cfg[\"hidden1\"], hidden2=baseline_cfg[\"hidden2\"]).to(device)\n",
    "\n",
    "opt_base = torch.optim.Adam(baseline.parameters(), lr=baseline_cfg[\"lr\"])\n",
    "\n",
    "_ = train_model(baseline, train_loader, val_loader, opt_base, criterion, device, epochs=EPOCHS)\n",
    "val_loss_b, val_acc_b = evaluate(baseline, val_loader, criterion, device)\n",
    "test_loss_b, test_acc_b = evaluate(baseline, test_loader, criterion, device)\n",
    "params_b = count_params(baseline)\n",
    "\n",
    "baseline_result = {\n",
    "    \"name\": (\"TuBaseline(BaselineAnterior)\" if use_user_baseline else f\"MLP(h1={baseline_cfg['hidden1']},h2={baseline_cfg['hidden2']})\"),\n",
    "    \"type\": \"BASELINE\",\n",
    "    \"val_acc\": val_acc_b,\n",
    "    \"test_acc\": test_acc_b,\n",
    "    \"params\": params_b,\n",
    "    \"model_obj\": baseline,\n",
    "}\n",
    "\n",
    "print(f\"Baseline -> val_acc={val_acc_b:.4f}, test_acc={test_acc_b:.4f}, params={params_b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f261ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resumen tabular de resultados\n",
    "import pandas as pd\n",
    "\n",
    "all_results = results_sorted + [baseline_result]\n",
    "df = pd.DataFrame([\n",
    "    {\"Modelo\": r[\"name\"], \"Tipo\": r[\"type\"], \"Val_Acc\": r[\"val_acc\"], \"Test_Acc\": r[\"test_acc\"], \"Parámetros\": r[\"params\"],\n",
    "     \"Acc_por_MillónParams\": (r[\"test_acc\"] / (r[\"params\"]/1_000_000)) if r[\"params\"]>0 else float(\"nan\")}\n",
    "    for r in all_results\n",
    "])\n",
    "\n",
    "# Orden por Test_Acc desc\n",
    "df = df.sort_values(by=\"Test_Acc\", ascending=False).reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bca46b",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 3 — Benchmark: CNN vs Línea base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tomamos la mejor CNN según validación\n",
    "best_cnn = next((r for r in results_sorted if r[\"type\"] == \"CNN\"), None)\n",
    "assert best_cnn is not None, \"No hay resultados de CNN.\"\n",
    "\n",
    "#  Matriz de confusión para la mejor CNN \n",
    "cm_cnn = confusion_matrix(best_cnn[\"model_obj\"], test_loader, num_classes=10, device=device)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm_cnn.numpy(), interpolation=\"nearest\")\n",
    "plt.title(\"Matriz de confusión – Mejor CNN\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Etiqueta real\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusión para la línea base \n",
    "cm_base = confusion_matrix(baseline_result[\"model_obj\"], test_loader, num_classes=10, device=device)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm_base.numpy(), interpolation=\"nearest\")\n",
    "plt.title(\"Matriz de confusión - Línea base (MLP)\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Etiqueta real\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen textual automático\n",
    "def pretty_pct(x: float) -> str:\n",
    "    return f\"{100.0*x:.2f}%\"\n",
    "\n",
    "print(\"\\nResumen benchmark \")\n",
    "print(f\"Mejor CNN: {best_cnn['name']} | Val_Acc={pretty_pct(best_cnn['val_acc'])} | Test_Acc={pretty_pct(best_cnn['test_acc'])} | Params={best_cnn['params']:,}\")\n",
    "print(f\"Baseline:  {baseline_result['name']} | Val_Acc={pretty_pct(baseline_result['val_acc'])} | Test_Acc={pretty_pct(baseline_result['test_acc'])} | Params={baseline_result['params']:,}\")\n",
    "\n",
    "eff_cnn  = best_cnn[\"test_acc\"] / (best_cnn[\"params\"] / 1_000_000)\n",
    "eff_base = baseline_result[\"test_acc\"] / (baseline_result[\"params\"] / 1_000_000)\n",
    "print(f\"Eficiencia (Acc por millón de parámetros) -> CNN: {eff_cnn:.4f}  vs  Baseline: {eff_base:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
